---
title: Hitting times and SMP
author: Dhruva Sambrani
date: 31 August
geometry: margin=1in
---
# Hitting times

For A subset S, define hitting time of A as 

$T_A  = \inf\{n\ge 0; X_n \in A\}$

Convention $\inf \phi = \infty$.

$T_A$ takes values in $\{0, 1, \dots\} \cup \{\infty\}$

1. Probability of hitting $A = P(T_A < \infty | X_0 = i) = P_i(T_A < \infty)$
2. Expected hitting time $E[T_A | X_0 = i] = E_i[T_A]$
3. Define vector $h^A = (h_i^A | i \in S)$, and $\psi^A = (\psi_i^A | i \in S)$ by $h_i^A = P_i(T_A < \infty)$, $\psi_i^A = E[T_A]$

**Theorem**: $h^A$ is the minimal solution of linear equations given by 

$$h^A = \begin{cases}
    h^A_1 = 1 & i \in A \\
    h^A_i = \sum_{j \in S} p_{ij} h_j^A & i \notin A
\end{cases}$$

_Proof_:

If $i \in A$, $h_i^A = 1$ is obvious

For $i \notin A$ write $T_A = 1 + T'_A$ where $T'_A$ is the time to hit $A$ after one step.

$h_i^A  = P_i(T_A < \infty)$

$= P_i (1+T_A' < \infty)$

$= \sum_j P_j(1+T_A' < \infty | x_1 = j) p_{ij}$

$= \sum_j P_j(T_A < \infty | x_0 = j) p_{ij}$

$= \sum_j h_j^A p_{ij}$

Let $\phi_A = (\phi_i^A, i \in S)$ be another solution.

Then, $\phi_i^A = 1 = h_i^A$ for $i \in A$

For $i \notin A$

$\phi_i^A = \sum p_{ij} \phi_j^A$

$= \sum_{j \in A} p_{ij} + \sum_{j \notin A} p_{ij} \phi_j^A$

$= \sum_{j \in A} p_{ij} + \sum_{j \notin A} p_{ij} \sum_{k} p_{jk} \phi_k^A$

$= \sum_{j \in A} p_{ij} + \sum_{j \notin A, k in A} p_{ij} p_{jk} + \sum_{j \notin A, k \notin A} p_{ij} p_{jk} \phi_k^A$

$\phi_i^A = P(T_a = 1) + P(T_a = 2) + P(T_a = 3) + \dots \ge P_i(T_A <= n)$.

Taking $\lim_{n \to \infty}$,

$$\phi_i^A \ge P_i(T_A < \infty) = h_i^A$$


**Theorem**: $\psi_A$ is the minimal solution of linear equations given by 

$$\begin{cases}
    \psi_i^A = 0                             &if i \in A \\
    \psi_i^A = \sum_{j \in A^C} p_{ij} \psi_j^A  &  if i \notin A
\end{cases}$$

_Proof_: 

If $i \in S$, obvious.

$E_i[T_A]  = E_i[1+T_A] = \sum_{j \in S} E[1+T_A' | X_1 = j]p_{ij}$

$= 1 + E[T_A | X_0 =j] p_{ij}$

$= 1 + \sum p_{ij} \psi_j^A$

Let $k$ be another solution.

On $i \in A$, this is obvious

For $i \notin A$,

$k_i^A = 1 + \sum_{j \notin A} p_{ij} \psi_j^A$

$= 1 + \sum_{j \notin A} p_{ij} (1 + \sum_{l \notin A} \sum_{jl} k_l^A)$

$= 1 + \sum_{j \notin A} p_{ij} + \sum_{j \in A^C, l \in A^C} p_{jl} k_l^A$

$= \sum_n P_i(T_A \ge n)$

> **Exercise**:
> Show $\sum_n P_i(T_A \ge n) = E_i[T_A]$

# Stopping times

$\{X_n\}$ is a random process which is also a MC.

Given a [filteration](https://en.wikipedia.org/wiki/Filtration_(probability_theory)) $F_n$ on $\Omega$,

$$\tau : \Omega \rightarrow W$$

is a stopping time if $\{\tau=n\}$ is measurable wrt $F_n$. That is, if $\{X_n\}$ is an MC, $\tau$ is a stopping time wrt $\{X_n\}$, if ${\tau = n}$ only depends on ($x_0, x_1, x_2, \dots, x_n$).

$$\{\tau = n\} \in F_n$$

**Eg**: $T_A$ is a ST.\
**Eg**: Exit time of A. $L_A = \sup\{n \ge 0; X_n \in A\}$; This is not a stopping time.

$F_T = \{A | A \cap \{T = n\} \in F_n\}$ ie $A \cap \{T = n\}$ only depends on ($X_0, \dots X_n$)

**To Show**:

For any $A \in \sigma(X_0, \dots, X_m)$

$$P(X_{m+1}=i_{m+1} \cap A | X_m = i) = p_{ii_{m+1}} p_{i_{m+1}i_{m+2}} \dots P(A | X_m=i)$$

Take $A = (X_0=i_0, X_1=i_1 \dots X_m = i)$

Then, 
$P(X_{m+1}=i_{m+1},\dots \cap A | X_m = i) = \frac{\lambda_{i_0} p_{i_0i_1} \dots }{P(X_m = i)} = p_{i_{m}i_{m+1}} p_{i_{m+1}i_{m+2}} \dots P(A | X_m=i)$

# Strong Markov Property

Let $\{X_n\}$ be an $MC(\lambda, P)$. $\tau$ is a Stopping Time with $\{X_n\}$. Suppose $\tau < \infty$ then conditioned on $\{\tau = n\}, (X_{\tau+1}, X_{\tau+2}, \dots)$ is $MC(\delta_n, P)$ and independent of PAST.

## Proof of SMP

Enough to show that for $A$ in $F_\tau$, 

$P(X_{\tau+1} = i_1, \dots, \cap A | X_\tau = i, \tau < infty) = p_{ii_1} p_{i_1i_2} \dots P(A|X_\tau = i, \tau < \infty)$

$p(x_{\tau+1} = i_1\dots \cap A, x_\tau=i, \tau=n) = P(X_n+1 = i_1\dots \cap A, X_n=i, \tau=n)$

$= P(X_n+1 = i_1\dots | A, X_n=i, \tau=n) P(A, X_n = i, \tau=n)$

$= P(X_n+1 = i_1\dots | X_n=i) P(A, X_n = i, \tau=n) \Leftarrow Because A in F_\tau$

$= p_{ii_1} p_{i_1i_2} \dots P(A, X_n = i, \tau=A)$

Hence,

$P(X_{\tau+1}= i_1, \dots, \cap A | X_\tau = i, \tau < \infty)  = \sum_n P(X_{\tau+1}= i_1, \dots, \cap A | X_\tau = i, \tau = n)$

$= p_{ii_1} p_{i_1i_2} \dots \sum_n P(A, X_n = i, \tau=A)$

Now, sum over n and divide by $P(X_i= i, \tau < \infty)$.

