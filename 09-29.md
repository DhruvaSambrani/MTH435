---
title: "MCMC: Sampling from a state space using Markov Chains"
author: Dhruva Sambrani
date: 27 October
geometry: margin=1in
---

## Spanning trees

Given $g = (V,E)$ with $|V| = n$, the number of spanning trees of $G = n^{n-2}$.

-   a spanning tree has $|v| - 1$ edges.
-   adding an edge creates an unique cycle

Every subgraph with $n-1$ edges and no cycles is a spanning tree.

Aim: to sample uniformly from the set of spanning trees of G.

1.  Let $X_t$ be a spanning tree $S_1$. Choose any edge $e$ from
    $E \\ E(S_1)$ uniformly at random.
2.  Let C be a unique cycle in $X_t \cup {e}$
3.  Choose $e'$ from $E(C)$ uniformly.
4.  Set $X_{t+1} = (X_t \\ \{e'\}) \cup {e}$

> **Exercise**: Write the transition matrix of this chain and show that
> it is irreducible, aperiodic and symmetric.

## Knapsack Problems

$m$ items each with value $v_i$ and weight $w_i$ for $1 < i < n$. Find $S = {i,}$ st $\arg\max_{\{i,\}} \sum_{i} v_i = S$ and $\sum_i w_i < C$.

Space of feasible solutions $S = {z : \langle w,z\rangle \le C}$

-   Start at some $z \in S$
-   Choose $j \in \{1,..n\}$ uniformly
-   $y = (z_1, z_2, \dots (1-z_{j})\dots, z_m)$.
-   If $\langle w, y\rangle \le C$,
    -   $X_{t+1} = y$
    -   otherwise $X_{t+1} = z$

However, the walk is more efficient if we instead sample j
$\pi(j) \propto e^{\beta\langle v,z\rangle}$ for some $\beta > 0$.

## Metropolis algorithm

S is a discrete space. Q a symmetric transition matrix on S and $\pi$,
the target distn.

Given $X_t, X_{t+1}$ is chosen to follow MC,

1.  Choose Y randomly according to Q, called the proposal.
    $P(Y=j | X_t = i) = q_{ij}$
2.  Define the acceptance probability $\alpha = \min\{1, \pi_Y/\pi_i\}$
3.  Let U \~ uniform(0,1). If $U \le alpha$ then $X_{t+1} = Y$.
    Otherwise $X_{t+1} = X_t$

$P_{ij} = q_{ij} * \alpha$

**Proposition**: If Q is irreducible, symmetric and $\pi$ a prob distn.
st $\pi>0 \forall i \in S$, then the Metropolis chain is also irr, and
reversible wrt $\pi$.

**Proof**:

Q is irr $\implies$ P irr

$\pi_i p_{ij} = \pi_i q_{ij} \alpha = q_{ij} \min\{\pi_i, \pi_j\} = \pi_j q_{ij} \min \{1, \pi_i/\pi_j\} = \pi_j p_{ji}$
